{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c3f0871",
   "metadata": {},
   "source": [
    "Detet citologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f01e45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca16dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Joelp/OneDrive/Imagens/tireoide/detect_citologia/detect-citologia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c826e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nfnets_keras import WSConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "335e7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():#modelo\n",
    "    inputs = tf.keras.Input(shape=(528, 528, 3))\n",
    "\n",
    "    ext_1 = tf.keras.layers.Conv2D(16, (7, 7), strides=(3, 3), use_bias=False)(inputs)\n",
    "    ext_1 = tf.keras.layers.BatchNormalization()(ext_1)\n",
    "    ext_1 = tf.nn.relu(ext_1)\n",
    "\n",
    "    # 73\n",
    "    ext_1 = tf.keras.layers.DepthwiseConv2D((7, 7), strides=(2, 2), use_bias=False)(ext_1)\n",
    "    ext_1 = tf.keras.layers.BatchNormalization()(ext_1)\n",
    "    ext_1 = tf.nn.relu(ext_1)\n",
    "    # 34\n",
    "\n",
    "    \"\"\"Parte dois\"\"\"\n",
    "    ext_2 = tf.keras.layers.Conv2D(16, (9, 9), strides=(3, 3), use_bias=False)(inputs)\n",
    "    ext_2 = tf.keras.layers.BatchNormalization()(ext_2)\n",
    "    ext_2 = tf.nn.relu(ext_2)\n",
    "    # 72\n",
    "\n",
    "    ext_2 = tf.keras.layers.DepthwiseConv2D((7, 7), strides=(2, 2), use_bias=False)(ext_2)\n",
    "    ext_2 = tf.keras.layers.BatchNormalization()(ext_2)\n",
    "    ext_2 = tf.nn.relu(ext_2)\n",
    "\n",
    "    ext_3 = tf.keras.layers.Concatenate()([ext_1, ext_2])\n",
    "\n",
    "    # Ramificação 3\n",
    "    ext_3_0 = tf.keras.layers.Conv2D(32, (7, 7), strides=(1, 1), use_bias=False)(ext_3)\n",
    "    ext_3_0 = tf.keras.layers.BatchNormalization()(ext_3_0)\n",
    "    ext_3_0 = tf.nn.relu(ext_3_0)\n",
    "    ext_3_0 = tf.keras.layers.MaxPooling2D()(ext_3_0)\n",
    "    # 14\n",
    "\n",
    "    ext_3_0 = tf.keras.layers.DepthwiseConv2D((7, 7), strides=(1, 1), use_bias=False)(ext_3_0)\n",
    "    ext_3_0 = tf.keras.layers.BatchNormalization()(ext_3_0)\n",
    "    ext_3_0 = tf.nn.relu(ext_3_0)\n",
    "    ext_3_0 = tf.keras.layers.MaxPooling2D()(ext_3_0)\n",
    "    # 4\n",
    "\n",
    "    ext_3_1 = tf.keras.layers.Conv2D(64, (5, 5), strides=(1, 1), use_bias=False)(ext_3)\n",
    "    ext_3_1 = tf.keras.layers.BatchNormalization()(ext_3_1)\n",
    "    ext_3_1 = tf.nn.relu(ext_3_1)\n",
    "    ext_3_1 = tf.keras.layers.MaxPooling2D()(ext_3_1)\n",
    "    # 7\n",
    "\n",
    "    ext_3_1 = tf.keras.layers.DepthwiseConv2D((5, 5), strides=(1, 1), use_bias=False)(ext_3_1)\n",
    "    ext_3_1 = tf.keras.layers.BatchNormalization()(ext_3_1)\n",
    "    ext_3_1 = tf.nn.relu(ext_3_1)\n",
    "    ext_3_1 = tf.keras.layers.MaxPooling2D()(ext_3_1)\n",
    "    # 1\n",
    "\n",
    "    # Ramificação 4\n",
    "    ext_4_0 = tf.keras.layers.Conv2D(32, (7, 7), strides=(1, 1), use_bias=False)(ext_1)\n",
    "    ext_4_0 = tf.keras.layers.BatchNormalization()(ext_4_0)\n",
    "    ext_4_0 = tf.nn.relu(ext_4_0)\n",
    "    ext_4_0 = tf.keras.layers.MaxPooling2D()(ext_4_0)\n",
    "\n",
    "    ext_4_0 = tf.keras.layers.DepthwiseConv2D((7, 7), strides=(1, 1), use_bias=False)(ext_4_0)\n",
    "    ext_4_0 = tf.keras.layers.BatchNormalization()(ext_4_0)\n",
    "    ext_4_0 = tf.nn.relu(ext_4_0)\n",
    "    ext_4_0 = tf.keras.layers.MaxPooling2D()(ext_4_0)\n",
    "    # 1\n",
    "\n",
    "    ext_4_1 = tf.keras.layers.Conv2D(64, (5, 5), strides=(1, 1), use_bias=False)(ext_1)\n",
    "    ext_4_1 = tf.keras.layers.BatchNormalization()(ext_4_1)\n",
    "    ext_4_1 = tf.nn.relu(ext_4_1)\n",
    "    ext_4_1 = tf.keras.layers.MaxPooling2D()(ext_4_1)\n",
    "\n",
    "    ext_4_1 = tf.keras.layers.DepthwiseConv2D((5, 5), strides=(1, 1), use_bias=False)(ext_4_1)\n",
    "    ext_4_1 = tf.keras.layers.BatchNormalization()(ext_4_1)\n",
    "    ext_4_1 = tf.nn.relu(ext_4_1)\n",
    "    ext_4_1 = tf.keras.layers.MaxPooling2D()(ext_4_1)\n",
    "    # 4\n",
    "\n",
    "    # Ramificação 5\n",
    "    ext_5_0 = tf.keras.layers.Conv2D(32, (7, 7), strides=(1, 1), use_bias=False)(ext_2)\n",
    "    ext_5_0 = tf.keras.layers.BatchNormalization()(ext_5_0)\n",
    "    ext_5_0 = tf.nn.relu(ext_5_0)\n",
    "    ext_5_0 = tf.keras.layers.MaxPooling2D()(ext_5_0)\n",
    "\n",
    "    ext_5_0 = tf.keras.layers.DepthwiseConv2D((7, 7), strides=(1, 1), use_bias=False)(ext_5_0)\n",
    "    ext_5_0 = tf.keras.layers.BatchNormalization()(ext_5_0)\n",
    "    ext_5_0 = tf.nn.relu(ext_5_0)\n",
    "    ext_5_0 = tf.keras.layers.MaxPooling2D()(ext_5_0)\n",
    "    # 2\n",
    "\n",
    "    ext_5_1 = tf.keras.layers.Conv2D(64, (5, 5), strides=(1, 1), use_bias=False)(ext_2)\n",
    "    ext_5_1 = tf.keras.layers.BatchNormalization()(ext_5_1)\n",
    "    ext_5_1 = tf.nn.relu(ext_5_1)\n",
    "    ext_5_1 = tf.keras.layers.MaxPooling2D()(ext_5_1)\n",
    "    # 15\n",
    "    ext_5_1 = tf.keras.layers.DepthwiseConv2D((5, 5), strides=(1, 1), use_bias=False)(ext_5_1)\n",
    "    ext_5_1 = tf.keras.layers.BatchNormalization()(ext_5_1)\n",
    "    ext_5_1 = tf.nn.relu(ext_5_1)\n",
    "    ext_5_1 = tf.keras.layers.MaxPooling2D()(ext_5_1)\n",
    "    # 5\n",
    "\n",
    "    ext_combination_2 = tf.keras.layers.Concatenate()([ext_3_1, ext_4_1, ext_5_1])\n",
    "    ext_combination_2 = tf.keras.layers.DepthwiseConv2D((7, 7), (3, 3), use_bias=False)(ext_combination_2)\n",
    "    ext_combination_2 = tf.keras.layers.BatchNormalization()(ext_combination_2)\n",
    "    ext_combination_2 = tf.nn.relu(ext_combination_2)\n",
    "\n",
    "    ext_combination_2 = tf.keras.layers.Flatten()(ext_combination_2)\n",
    "\n",
    "    ext_4 = tf.keras.layers.Flatten()(ext_4_0)\n",
    "    ext_3 = tf.keras.layers.Flatten()(ext_3_0)\n",
    "    ext_5 = tf.keras.layers.Flatten()(ext_5_0)\n",
    "\n",
    "    x = tf.matmul(ext_4,ext_3)\n",
    "    x = tf.matmul(x, ext_5)\n",
    "\n",
    "    cla = tf.keras.layers.Concatenate()([x, ext_combination_2])\n",
    "    cla = tf.keras.layers.Dense(43, activation='elu', use_bias=False)(cla)\n",
    "    cla = tf.keras.layers.Dropout(0.3)(cla)\n",
    "    cla = tf.keras.layers.Dense(1, activation='sigmoid', use_bias=False)(cla)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=cla)\n",
    "    model.summary()\n",
    "    model.compile(tf.keras.optimizers.Adam(),\n",
    "                       loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                       metrics=tf.keras.metrics.sparse_categorical_accuracy\n",
    "                       )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a50756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import large_image\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af076b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom data-generator\n",
    "# referencia: https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3\n",
    "# x = numpy.shape(batch_size, input_height, input_width, input_channel)\n",
    "# https://dzlab.github.io/dltips/en/keras/data-generator/\n",
    "\n",
    "\"\"\"\n",
    "Gera imagens de tamanho rxr a partir de um arquivo Whole Slide Imaging (WSI).\n",
    "Os arquivos aceitos incluem mrxs e svs.\n",
    "\n",
    "\"\"\"\n",
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_size=64,\n",
    "                 r=528,\n",
    "                 path_files=None,\n",
    "                 n_classes=2,\n",
    "                 iterations=10,\n",
    "                 netative_iterators = None,\n",
    "                 test_mode = False,\n",
    "                 path_positive=None):\n",
    "        \"\"\"\n",
    "        :param batch_size: (int) tamanho do pacote. é o tanto de imagens por cada iteração de treinamento do modelo.\n",
    "        :param r: (int) resolução da imagem de saída. rxr\n",
    "        :param path_files: (list) de tupla (string, string) = (uri_file, classe). uri_file é o link completo do arquivo.\n",
    "        classe é a classe correpondente.\n",
    "        :param n_classes: numero de classes.\n",
    "        :param iterations: este gerador consegue gerar infinitas imagens, então limite o numero de interações por epoca.\n",
    "        \"\"\"\n",
    "        self.iterations = iterations\n",
    "        self.path_files = path_files\n",
    "        self.batch_size = batch_size\n",
    "        self.i = 0  # posição do arquivo, que dá o iterator, não é a posição no iterator.\n",
    "        self.r = r\n",
    "        self.p = -1\n",
    "        self.n_classes = n_classes\n",
    "        self.test_mode = test_mode\n",
    "        self.path_positive = path_positive\n",
    "        self.p_positive = 0\n",
    "        self.positive_iterator = glob.glob(self.path_positive+\"/*.jpg\")\n",
    "        \n",
    "        #inicialização\n",
    "        if netative_iterators is None:\n",
    "            self._instances_iterators()\n",
    "            self.init_iterators()\n",
    "        else:\n",
    "            self.netative_iterators = netative_iterators\n",
    "\n",
    "    \"\"\"\n",
    "    Para cada iterator p, itera-se até a primeira imagem válida\n",
    "    \"\"\"\n",
    "    def init_iterators(self):\n",
    "\n",
    "        for p in range(self.n_classes):\n",
    "            print(\"Inicializando o iterator: {}, classe {}\".format(p, self.netative_iterators[p][1]))\n",
    "            self.p = p\n",
    "            image_array = self._next()\n",
    "            mean_rgb = np.mean(image_array[:, :, :4], axis=(0, 1))\n",
    "\n",
    "            while self._not_content_RGBA(mean_rgb):\n",
    "                image_array = self._next()\n",
    "                mean_rgb = np.mean(image_array[:, :, :4], axis=(0, 1))\n",
    "        print(\"Inicialização dos iterators completa.\")\n",
    "        self.p = -1 # posição do iterator na lista de iterators instanciados\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Modificar uma instancia da posição p da lista de iterators\n",
    "    Usada para alternar entre os arquivos sem perder a instancia do iterator\n",
    "    \"\"\"\n",
    "    def _change_instance(self, p):\n",
    "\n",
    "        if self.i < len(self.path_files) - 1:\n",
    "            self.i = self.i + 1\n",
    "            # se tiverem mais arquivos para serem lidos, acrescenta.\n",
    "        else:\n",
    "            # se não houverem mais arquivos, volta para o primeiro.\n",
    "            self.i = 0\n",
    "\n",
    "        ts = large_image.getTileSource(self.path_files[self.i][0])\n",
    "        iterator = ts.tileIterator(\n",
    "                tile_size=dict(width=self.r, height=self.r)\n",
    "            )\n",
    "        self.netative_iterators[p] = (iterator, self.path_files[self.i][1]) #tupla = (iterator,classe)\n",
    "\n",
    "    \"\"\"\n",
    "    Criar a lista de iterators\n",
    "    \"\"\"\n",
    "    def _instances_iterators(self):\n",
    "\n",
    "        self.netative_iterators = []\n",
    "\n",
    "        for i in range(self.n_classes):\n",
    "            ts = large_image.getTileSource(self.path_files[self.i][0])\n",
    "\n",
    "            iterator = ts.tileIterator(\n",
    "                tile_size=dict(width=self.r, height=self.r)\n",
    "            )\n",
    "            self.netative_iterators.append((iterator, self.path_files[self.i][1])) #tupla = (iterator, classe)\n",
    "            self.i = self.i + 1\n",
    "\n",
    "    # return label encoder: [1,0,..,0] if cla=0, [0,1,...,0] if cla=1...\n",
    "    def to_categorical(self, cla):\n",
    "        return to_categorical(cla, num_classes=self.n_classes)\n",
    "\n",
    "    def _not_content_RGBA(self, p):  # Tome RGB como três eixos ordenados. O A corresponde ao\n",
    "        \"\"\"\n",
    "        Se a média dos valores RGB estão próximos de 1, então provavelmente são imagens\n",
    "        em branco.\n",
    "        Os pixels estão entre 0 e 1.\n",
    "        \"\"\"\n",
    "        if self.test_mode:\n",
    "            return False\n",
    "        else:\n",
    "            return (p[0] - 1) ** 2 + (p[1] - 1) ** 2 + (p[2] - 1) ** 2 <= 0.2 or (p[0]) ** 2 + (p[1]) ** 2 + (\n",
    "            p[2]) ** 2 <= 0.2 or p[3] < 0.9\n",
    "\n",
    "    \"\"\"\n",
    "    Pegar a proxima tile do arquivo. Se não houver, muda de arquivo.\n",
    "    \"\"\"\n",
    "    def _next(self):\n",
    "        try:\n",
    "            image_array = next(self.netative_iterators[self.p][0])['tile'] / 255.\n",
    "        except:\n",
    "            #mudar a instancia do iterator da posição p para o do próximo arquivo disponível\n",
    "            self._change_instance(self.p)\n",
    "            image_array = next(self.netative_iterators[self.p][0])['tile'] / 255.\n",
    "\n",
    "        return image_array\n",
    "\n",
    "    def _next_item_i(self):\n",
    "\n",
    "        #alternar entre os tipos de classes\n",
    "        if self.p < self.n_classes - 1:\n",
    "            self.p = self.p + 1\n",
    "        else:\n",
    "            self.p = 0\n",
    "\n",
    "        X = list()\n",
    "        Y = list()\n",
    "        #obter uma imagem válida\n",
    "        i = 0\n",
    "        # imagens que têm nivel de transparência ou são quase totalmente preta ou\n",
    "        # quase totalmente brancas não são inclusas\n",
    "        while i < self.batch_size:\n",
    "            image_array = self._next()\n",
    "            mean_rgb = np.mean(image_array[:, :, :4], axis=(0, 1))\n",
    "\n",
    "            if not self._not_content_RGBA(mean_rgb):\n",
    "                image_array = image_array[:, :, :3]\n",
    "                X.append(image_array)\n",
    "                Y.append([0])\n",
    "                i = i + 1\n",
    "\n",
    "        return np.array(X), np.array(Y)\n",
    "\n",
    "    def _next_positive(self):\n",
    "\n",
    "        \"\"\"\n",
    "       Rotações e espelhamentos são aceitáveis como imagens geradas porque preservam a disposição dos componentes\n",
    "       na imagem\n",
    "       \"\"\"\n",
    "\n",
    "        data_generator = ImageDataGenerator(\n",
    "            rotation_range=90,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            zoom_range = 0.3,\n",
    "            rescale= 1./255\n",
    "        )\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        uri_image = self.positive_iterator[self.p_positive]\n",
    "        image_array = np.array(Image.open(uri_image))\n",
    "        image_array = image_array.reshape((1,) + image_array.shape)\n",
    "        X = []\n",
    "        Y = []\n",
    "        for image in data_generator.flow(image_array, batch_size=1):\n",
    "            X.append(image[0])\n",
    "            Y.append([1])\n",
    "\n",
    "            i = i+1\n",
    "\n",
    "            if i == self.batch_size:\n",
    "                break\n",
    "                \n",
    "        if self.p_positive < len(self.positive_iterator)-1:\n",
    "            self.p_positive = self.p_positive + 1\n",
    "        else:\n",
    "            self.p_positive = 0\n",
    "            \n",
    "        return np.array(X), np.array(Y)\n",
    "    \"\"\"\n",
    "    Extrai uma imagem válida do arquivo e cria bathc_size imagens e retorna uma tupla (X_batch,y_batch)\n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if index % 2 == 0:\n",
    "            return self._next_item_i()\n",
    "        return self._next_positive()\n",
    "\n",
    "    def __len__(self):\n",
    "        # quantidade de batch\n",
    "        return self.iterations\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        #Não é preciso reorganizar os dados.\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1aac6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição das classes, pasta de trabalho, treino, etc\n",
    "\n",
    "path = \"/media/joel/Windows/Users/Joelp/OneDrive/Imagens/tireoide/arquivos-tireoide/arquivos-escaners\"\n",
    "files = {\n",
    "    \"DigitalSlide_D7M_8S_1.mrxs\":0,\n",
    "    \"DigitalSlide_D7M_4S_1.mrxs\":1,\n",
    "    \"DigitalSlide_D7M_7S_1.mrxs\":0,\n",
    "    \"DigitalSlide_D7M_5S_1.mrxs\": 1,\n",
    "    \"DigitalSlide_D7M_10S_1.mrxs\":0,\n",
    "    \"DigitalSlide_D7M_1S_1.mrxs\":1,\n",
    "    \"DigitalSlide_D7M_6S_1.mrxs\":0,\n",
    "    \"DigitalSlide_D7M_2S_1.mrxs\":1,\n",
    "    \"DigitalSlide_D7M_9S_1.mrxs\":0,\n",
    "    \"DigitalSlide_D7M_3S_1.mrxs\":1\n",
    "}\n",
    "classes = {\n",
    "    0:\"benigno\",\n",
    "    1:\"maligno\"\n",
    "}\n",
    "\n",
    "#dados de treino e de validação\n",
    "i = 0\n",
    "train = []\n",
    "validation = []\n",
    "for key in files:\n",
    "  uri = path+\"/\"+key\n",
    "  a = (uri,files[key])\n",
    "  \n",
    "  if i < 8:\n",
    "    #dados de treino\n",
    "    train.append(a)\n",
    "  else:\n",
    "    validation.append(a)\n",
    "\n",
    "  i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f15d2493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializando o iterator: 0, classe 0\n",
      "Inicializando o iterator: 1, classe 1\n",
      "Inicialização dos iterators completa.\n",
      "Inicializando o iterator: 0, classe 0\n",
      "Inicializando o iterator: 1, classe 1\n",
      "Inicialização dos iterators completa.\n"
     ]
    }
   ],
   "source": [
    "data_gen_train = CustomDataset(batch_size=64,\n",
    "                 r=528,\n",
    "                 path_files=train,\n",
    "                 n_classes=2,\n",
    "                 iterations=10,\n",
    "                 netative_iterators=None,\n",
    "                 test_mode = False,\n",
    "                 path_positive=\"/media/joel/Windows/Users/Joelp/OneDrive/Imagens/tireoide/detect_citologia/citologia\")\n",
    "\n",
    "data_gen_val = CustomDataset(batch_size=64,\n",
    "                 r=528,\n",
    "                 path_files=validation,\n",
    "                 n_classes=2,\n",
    "                 iterations=10,\n",
    "                 netative_iterators = None,\n",
    "                 test_mode = False,\n",
    "                 path_positive=\"/media/joel/Windows/Users/Joelp/OneDrive/Imagens/tireoide/detect_citologia/citologia\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aab01f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'ws_conv2d/kernel:0' shape=(7, 7, 3, 8) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'ws_conv2d/bias:0' shape=(8,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'ws_conv2d_1/kernel:0' shape=(7, 7, 8, 12) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'ws_conv2d_1/bias:0' shape=(12,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'ws_conv2d_2/kernel:0' shape=(7, 7, 12, 16) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'ws_conv2d_2/bias:0' shape=(16,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'ws_conv2d_3/kernel:0' shape=(3, 3, 16, 18) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'ws_conv2d_3/bias:0' shape=(18,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_4), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'ws_conv2d_4/kernel:0' shape=(7, 7, 16, 18) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_4), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'ws_conv2d_4/bias:0' shape=(18,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 528, 528, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution (TFOpLambda)  (None, 522, 522, 8)  0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.bias_add (TFOpLambda)     (None, 522, 522, 8)  0           tf.nn.convolution[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 522, 522, 8)  32          tf.nn.bias_add[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_30 (TFOpLambda)      (None, 522, 522, 8)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 261, 261, 8)  0           tf.nn.relu_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_20 (DepthwiseC (None, 255, 255, 8)  400         max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_1 (TFOpLambda (None, 249, 249, 12) 0           depthwise_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.bias_add_1 (TFOpLambda)   (None, 249, 249, 12) 0           tf.nn.convolution_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_31 (TFOpLambda)      (None, 249, 249, 12) 0           tf.nn.bias_add_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 124, 124, 12) 0           tf.nn.relu_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_21 (DepthwiseC (None, 118, 118, 12) 600         max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 118, 118, 12) 48          depthwise_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 59, 59, 12)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_2 (TFOpLambda (None, 53, 53, 16)   0           max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.bias_add_2 (TFOpLambda)   (None, 53, 53, 16)   0           tf.nn.convolution_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 53, 53, 16)   64          tf.nn.bias_add_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_32 (TFOpLambda)      (None, 53, 53, 16)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_22 (DepthwiseC (None, 47, 47, 16)   800         tf.nn.relu_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 47, 47, 16)   64          depthwise_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_33 (TFOpLambda)      (None, 47, 47, 16)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 23, 23, 16)   0           tf.nn.relu_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_3 (TFOpLambda (None, 21, 21, 18)   0           max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_4 (TFOpLambda (None, 21, 21, 18)   0           tf.nn.relu_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.bias_add_3 (TFOpLambda)   (None, 21, 21, 18)   0           tf.nn.convolution_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.bias_add_4 (TFOpLambda)   (None, 21, 21, 18)   0           tf.nn.convolution_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 21, 21, 18)   72          tf.nn.bias_add_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 21, 21, 18)   72          tf.nn.bias_add_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_34 (TFOpLambda)      (None, 21, 21, 18)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_35 (TFOpLambda)      (None, 21, 21, 18)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 21, 21, 18)   0           tf.nn.relu_34[0][0]              \n",
      "                                                                 tf.nn.relu_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_23 (DepthwiseC (None, 15, 15, 18)   900         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 15, 15, 18)   36          depthwise_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.nn.relu_36 (TFOpLambda)      (None, 15, 15, 18)   0           layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 18)     0           tf.nn.relu_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 882)          0           average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            883         flatten_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,971\n",
      "Trainable params: 3,795\n",
      "Non-trainable params: 176\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c7f1d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model(\"/media/joel/New Volume/work/TireoideWork/detector-tiles/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f09fa77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(), \n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['binary_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4841e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c326792",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_h5 = \"/media/joel/New Volume/work/TireoideWork/detector-tiles/model-11-08-2021.h5\"\n",
    "checkpoint = ModelCheckpoint(file_h5, monitor='loss', save_best_only=True, verbose=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "148e66b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "694db2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 95 images belonging to 2 classes.\n",
      "Found 19 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        \"train\",\n",
    "        #validation_split=0.2,\n",
    "        #subset=\"training\",\n",
    "        seed=36,\n",
    "        image_size=(528, 528),\n",
    "        batch_size=32)\n",
    "\n",
    "    # meus dados de entrada já estão normalizados\n",
    "    # train_ds = train_ds.map(process)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        \"/validation\",\n",
    "        #validation_split=0.2,\n",
    "        #subset=\"validation\",\n",
    "        seed=36,\n",
    "        image_size=(528, 528),\n",
    "        batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419821c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.7719 - binary_accuracy: 0.4842 - val_loss: 0.7117 - val_binary_accuracy: 0.4737\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.18152\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 17s 5s/step - loss: 0.7160 - binary_accuracy: 0.5579 - val_loss: 0.7321 - val_binary_accuracy: 0.4737\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.18152\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.6751 - binary_accuracy: 0.5789 - val_loss: 0.7172 - val_binary_accuracy: 0.4737\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.18152\n",
      "Epoch 4/1000\n",
      "1/3 [=========>....................] - ETA: 12s - loss: 0.6583 - binary_accuracy: 0.5938"
     ]
    }
   ],
   "source": [
    "eff_history = model.fit(train_ds,\n",
    "                          validation_data = val_ds,\n",
    "                          epochs = 1000,\n",
    "                          verbose=1,\n",
    "                          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11a18e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

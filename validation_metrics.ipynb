{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ryp8Zspmx3_n",
   "metadata": {
    "id": "ryp8Zspmx3_n"
   },
   "source": [
    "### Validation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea97d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "-h2lpTJCx6wu",
   "metadata": {
    "id": "-h2lpTJCx6wu"
   },
   "outputs": [],
   "source": [
    "#this method return values to calculate ROC and AUC score\n",
    "def confusion_matrix(y_true,y_score, threshold):\n",
    "    \n",
    "    t_p = 0 #true positive\n",
    "    f_p = 0 #false positive\n",
    "    f_n = 0 #false negative\n",
    "    t_n = 0 #true negative\n",
    "    qtd_p = 0 #negative quantity\n",
    "    qtd_n = 0 #netative quantity\n",
    "    \n",
    "    for i in range(len(y_true)):\n",
    "        \n",
    "        if y_true[i] == 1:\n",
    "            #positive\n",
    "            qtd_p+=1\n",
    "            \n",
    "            if y_score[i] >= threshold:\n",
    "                #true positive\n",
    "                t_p += 1\n",
    "            else:\n",
    "                #false negative\n",
    "                f_n += 1\n",
    "                \n",
    "        else:\n",
    "            #negative\n",
    "            qtd_n += 1\n",
    "            \n",
    "            if y_score[i] >= threshold:\n",
    "                #false positive\n",
    "                f_p += 1\n",
    "                \n",
    "            else:\n",
    "                #true negative\n",
    "                t_n += 1\n",
    "                    \n",
    "    return {\n",
    "        \"threshold\": threshold,\n",
    "        \"t_p\":t_p,\n",
    "        \"f_p\":f_p,\n",
    "        \"f_n\":f_n,\n",
    "        \"t_n\":t_n,\n",
    "        \"qtd_p\":qtd_p,\n",
    "        \"qtd_n\":qtd_n\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc24252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_true_y_score(model, class_names,path):\n",
    "    \n",
    "    y_true = []\n",
    "    y_score = []\n",
    "    \n",
    "    for cla in class_names:\n",
    "        for image in os.listdir(path+\"/\"+class_names[cla]): #iterate by all files in the path, make sure that exists only images\n",
    "            img = keras.preprocessing.image.load_img(path+\"/\"+class_names[cla]+\"/\"+image)\n",
    "            img_array = tf.keras.preprocessing.image.img_to_array(img)# / 255. not if the image already scaled by 255\n",
    "            img_array = tf.expand_dims(img_array, 0) #transform to shape = (1, r, r), where r is the resolution\n",
    "\n",
    "            predictions = model.predict(img_array)\n",
    "            y_score.append(predictions[0][0])\n",
    "            y_true.append(cla)\n",
    "                \n",
    "    return y_true, y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "62ccd9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(t_p,f_p):\n",
    "    return t_p/(t_p+f_p)\n",
    "\n",
    "#true positive and false positive rate\n",
    "def accuracy(t_p, t_n, f_p, f_n):\n",
    "    return (t_p+t_p)/(t_n+f_p+f_n+t_p)\n",
    "\n",
    "#sensitivity = true positive rate\n",
    "def recall(t_p, f_n):\n",
    "    return t_p/(t_p+f_n)\n",
    "\n",
    "#false positive rate = 1 - specifity\n",
    "def f_p_rate(f_p, t_n):\n",
    "    return f_p/(f_p+t_n)\n",
    "\n",
    "#true negative rate\n",
    "def specificity(t_n, f_p):\n",
    "    return t_n/(t_n+f_p)\n",
    "\n",
    "def F_beta(precision, recall, beta=1):\n",
    "    return (1+beta**2)*precision*recall/precision*recall*beta**2\n",
    "\n",
    "\n",
    "def best_threshold_by_roc(y_true, y_score):\n",
    "    #add all results for differ threholds\n",
    "    \n",
    "    best_d = None\n",
    "    best_matrix = None\n",
    "    \n",
    "    for threshold in range(0, 1, 1/1000):\n",
    "        matrix_t = confusion_matrix(y_true, y_score, threshold)\n",
    "        \n",
    "        #curve roc with the x and y axis\n",
    "        y = recall(matrix_t['t_p'],matrix_t['f_n'])\n",
    "        x = f_p_rate(matrix_t['f_p'],matrix_t['t_p'])\n",
    "        \n",
    "        #calculate the distance between optimum and the position i\n",
    "        di = np.sqrt(x**2+(1-y)**2)\n",
    "        \n",
    "        if best_d is None:\n",
    "            best_d = di\n",
    "            best_matrix = matrix_t\n",
    "        elif best_d > di:\n",
    "            best_d = di\n",
    "            matrix_t = matrix_t\n",
    "        \n",
    "    return matrix_t\n",
    "\n",
    "#area under the curve of roc\n",
    "def AUC_score(x,y):\n",
    "    \n",
    "    a = 0\n",
    "    for i in range(1,len(x)):\n",
    "        a += (x[i]-x[i-1:i])*y[i-1]\n",
    "        \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b3240",
   "metadata": {},
   "source": [
    "**ROC curve** True positive rate x False positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    0: 'benigno',\n",
    "    1: 'maligno'\n",
    "}\n",
    "\n",
    "models_path = \"\"\n",
    "images_path= \"\"\n",
    "\n",
    "models_scores = dict() #model_uri: (auc_score, accu_score)\n",
    "\n",
    "#find the best model by AUC or ACCURACY or F1 score\n",
    "for model_uri in glob.glob(models_path+\"/*.h5\"):\n",
    "    model_i = tf.keras.models.load_model(model_uri)\n",
    "    model_name = os.path.split(model_uri)[-1]\n",
    "    \n",
    "    y_true, y_pred = y_true_y_score(model, class_names, images_path)\n",
    "\n",
    "    s1 = roc_auc_score(y_true, y_pred) # accuracy_score(y_true, y_pred, normalize=False), f1_score(y_true, y_pred)\n",
    "    models_scores[model_name] = np.array([s1])\n",
    "    \n",
    "models_scores_df = pd.DataFrame(models_scores).transpose()\n",
    "models_scores_df[2] = (models_scores_df[0]+models_scores_df[1])/3 #mean between the three scores\n",
    "models_scores_df = models_scores_df.sort_values(by=2, axis=0, ascending=False)\n",
    "\n",
    "best_model = tf.keras.models.load_model(models_path+\"/\"+models_scores_df.index[0])\n",
    "y_true, y_pred = y_true_y_score(model, class_names, images_path)\n",
    "\n",
    "#print the details of best model with the best threshold\n",
    "best_threshold_by_roc(y_true, y_score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Classification_effcientnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
